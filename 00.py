
from nltk.tokenize import word_tokenize

text = "Hello, world I'll! don't"

tokens = word_tokenize(text)
print(tokens)

